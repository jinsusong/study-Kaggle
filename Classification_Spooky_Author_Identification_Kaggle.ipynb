{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Spooky Author Identification_Kaggle.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMpC5E+be+UXSozpX7S6Lpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/study-Kaggle/blob/main/Classification_Spooky_Author_Identification_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle Spooky Author Identification 데이터 불러오기 "
      ],
      "metadata": {
        "id": "fH3HavkYSLPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2-tBr0sPiLh"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "metadata": {
        "id": "o_TsaUm9RK2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Permission Warning 방지\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!pwd"
      ],
      "metadata": {
        "id": "HxKQxS0wPkNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c spooky-author-identification"
      ],
      "metadata": {
        "id": "MPTuOJAoPsTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "metadata": {
        "id": "Smx1GhkAQI_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 압축 해제"
      ],
      "metadata": {
        "id": "AcXDnZ8ERxrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!unzip sample_submission.zip -d data/\n",
        "!unzip test.zip -d data/\n",
        "!unzip train.zip -d data/"
      ],
      "metadata": {
        "id": "9S31m9IcSQON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 확인하기 "
      ],
      "metadata": {
        "id": "IRAY-sgqSXyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "label_cols = ['author']\n",
        "train = pd.read_csv(\"data/train.csv\")\n",
        "print(len(train))\n",
        "#len_eap = train['author'] == 'EAP'\n",
        "#len_eap\n",
        "train.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "8thF4OoPTP0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test = pd.read_csv(\"data/test.csv\")\n",
        "test.head()\n"
      ],
      "metadata": {
        "id": "cp2y829NTQnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess Data "
      ],
      "metadata": {
        "id": "w9TY8aFDVFZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = list(train[\"text\"])\n",
        "y = list(train[\"author\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(bert_train['text'], bert_train['target'], test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "cXVpkJH1xYPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train\n",
        "#y_train"
      ],
      "metadata": {
        "id": "cJWwN6ToQS9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['author']\n",
        "# labels =  train['author'].values\n",
        "# print(labels)\n",
        "\n",
        "# train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=0, test_size=0.1)\n",
        "# train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=0, test_size=0.1)\n",
        "\n",
        "# train_size = len(train_inputs)\n",
        "# validation_size = len(validation_inputs)\n"
      ],
      "metadata": {
        "id": "muVAleVTN33W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "HDsb-ejYuZD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 버트 토크나이저 로드 "
      ],
      "metadata": {
        "id": "d4D0X3kGTlmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "bert_model_name = 'bert-base-uncased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n"
      ],
      "metadata": {
        "id": "DdXSQeODUbDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenized"
      ],
      "metadata": {
        "id": "hNBrXu-ax4fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(X_train, padding=True, truncation=True, max_length=512,add_special_tokens=True, return_attention_mask=True) \n",
        "val_encodings = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "test_encodings = tokenizer(y_train, padding=True, truncation=True, max_length=512,add_special_tokens=True, return_attention_mask=True) \n",
        "test_val_encodings = tokenizer(y_val, padding=True, truncation=True, max_length=512)\n",
        "len(train_encodings)\n",
        "\n",
        "\n",
        "# input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],input_dict[\"token_type_ids\"], input_dict['attention_mask'])"
      ],
      "metadata": {
        "id": "qWCNIZy_yJh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(X_train, padding=True, truncation=True, max_length=512,add_special_tokens=True, return_attention_mask=True) "
      ],
      "metadata": {
        "id": "t7U-BaZ_Wbwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_input_ids, x_test_token_type_ids, x_test_attention_mask = (train_encodings[\"input_ids\"],train_encodings[\"token_type_ids\"], train_encodings['attention_mask'])\n",
        "x_val_input_ids, x_val_token_type_ids, x_val_attention_mask = (val_encodings[\"input_ids\"],val_encodings[\"token_type_ids\"], val_encodings['attention_mask'])\n",
        "y_test_input_ids, y_test_token_type_ids, y_test_attention_mask = (test_encodings[\"input_ids\"],test_encodings[\"token_type_ids\"], test_encodings['attention_mask'])\n",
        "y_val_input_ids, y_val_token_type_ids, y_val_attention_mask = (test_val_encodings[\"input_ids\"],test_val_encodings[\"token_type_ids\"], test_val_encodings['attention_mask'])\n"
      ],
      "metadata": {
        "id": "IYloddX7WbpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test_input_ids[0])\n",
        "print(x_test_token_type_ids[0])\n",
        "print(x_test_attention_mask[0])\n",
        "print(y_test_input_ids[0])"
      ],
      "metadata": {
        "id": "Wfn15pYVES-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 셋으로 변환"
      ],
      "metadata": {
        "id": "T2Q_8LBhEc08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# train_data = tf.data.Dataset.from_tensor_slices(train_encodings)\n",
        "# train_val_data = tf.data.Dataset.from_tensor_slices(val_encodings)\n",
        "# y_data = tf.data.Dataset.from_tensor_slices(test_encodings)\n",
        "# y_val_data = tf.data.Dataset.from_tensor_slices(test_val_encodings)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_test_input_ids, x_test_token_type_ids, x_test_attention_mask))\n",
        "train_val_data = tf.data.Dataset.from_tensor_slices((x_val_input_ids, x_val_token_type_ids, x_val_attention_mask))\n",
        "y_data = tf.data.Dataset.from_tensor_slices((y_test_input_ids, y_test_token_type_ids, y_test_attention_mask))\n",
        "y_val_data = tf.data.Dataset.from_tensor_slices((y_val_input_ids, y_val_token_type_ids, y_val_attention_mask))\n",
        "\n"
      ],
      "metadata": {
        "id": "b6x7R27FL6yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 셋 batch 사용해보기\n",
        "print(train_data)\n",
        "batch_size = 32\n",
        "batch_train_data = train_data.batch(batch_size)\n",
        "batch_train_val_data = train_val_data.batch(batch_size)\n",
        "batch_y_data = y_data.batch(batch_size)\n",
        "batch_y_val_data = y_val_data.batch(batch_size)\n",
        "\n",
        "print(batch_train_data)"
      ],
      "metadata": {
        "id": "4UzFIkvQNypD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y label 데이터 셋에 포함 시키기 , 실패 , 학습이 안됨\n",
        "# 학습 시  y 데이터를 넣어야함 ㅜㅜ\n",
        "# 데이터 형태 문제인듯, y label을 어떻게 넣는지 모르겠다.\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_encodings[\"input_ids\"], train_encodings[\"token_type_ids\"],train_encodings['attention_mask'], test_encodings[\"input_ids\"]))\n",
        "# train_val_data = tf.data.Dataset.from_tensor_slices((x_val_input_ids, x_val_token_type_ids, y_val_input_ids))"
      ],
      "metadata": {
        "id": "VeZHrjP1tSw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "vlIHXiCouisQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)\n",
        "i = 0\n",
        "for element in train_data:\n",
        "  i += 1\n",
        "  print(element)\n",
        "  if i > 1 : break"
      ],
      "metadata": {
        "id": "PYjm-wrCQ9ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-phsGcMzL6Ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model "
      ],
      "metadata": {
        "id": "l7UDYCYPU_OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(bert_model_name)"
      ],
      "metadata": {
        "id": "q463bka5VDzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data \n",
        "# train_val_data \n",
        "# y_data \n",
        "# y_val_data \n",
        "\n",
        "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# model.compile(optimizer='adam',loss=loss)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n"
      ],
      "metadata": {
        "id": "HrTWzmGWQbGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary"
      ],
      "metadata": {
        "id": "Fa8JQFkkqxY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 구조 확인하기 \n",
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "v8CA0sdMr-ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, epochs=1, batch_size=32)\n",
        "#model.fit(batch_train_data, validation_data=train_val_data, epochs=1)"
      ],
      "metadata": {
        "id": "PcDEZjBRYZip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gPDE3KbzLNZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4SZZOlRLs5Pv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}